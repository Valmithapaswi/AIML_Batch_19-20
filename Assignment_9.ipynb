{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+kkO0LtJ2+wvAv2MA687F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Valmithapaswi/AIML_Batch_19-20/blob/main/Assignment_9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "\n",
        "df = pd.read_csv('loan_data.csv')\n",
        "\n",
        "\n",
        "df.info()\n",
        "\n",
        "\n",
        "df.describe()\n",
        "\n",
        "\n",
        "df.head()\n",
        "\n",
        "\n",
        "print(\"Follwoing is a breakup of credit approval status. 1 means approved credit, 0 means not approved.\")\n",
        "print(df['credit.policy'].value_counts())\n",
        "\n",
        "\n",
        "\n",
        "df[df['credit.policy']==1]['fico'].plot.hist(bins=30,alpha=0.5,color='blue', label='Credit.Policy=1')\n",
        "df[df['credit.policy']==0]['fico'].plot.hist(bins=30,alpha=0.5, color='red', label='Credit.Policy=0')\n",
        "plt.legend(fontsize=15)\n",
        "plt.title (\"Histogram of FICO score by approved or disapproved credit policies\", fontsize=16)\n",
        "plt.xlabel(\"FICO score\", fontsize=14)\n",
        "\n",
        "Text(0.5, 0, 'FICO score')\n",
        "\n",
        "\n",
        "sns.boxplot(x=df['credit.policy'],y=df['int.rate'])\n",
        "plt.title(\"Interest rate varies between risky and non-risky borrowers\", fontsize=15)\n",
        "plt.xlabel(\"Credit policy\",fontsize=15)\n",
        "plt.ylabel(\"Interest rate\",fontsize=15)\n",
        "\n",
        "Text(0, 0.5, 'Interest rate')\n",
        "\n",
        "\n",
        "sns.boxplot(x=df['credit.policy'],y=df['log.annual.inc'])\n",
        "plt.title(\"Income level does not make a big difference in credit approval odds\", fontsize=15)\n",
        "plt.xlabel(\"Credit policy\",fontsize=15)\n",
        "plt.ylabel(\"Log. annual income\",fontsize=15)\n",
        "\n",
        "Text(0, 0.5, 'Log. annual income')\n",
        "\n",
        "\n",
        "sns.boxplot(x=df['credit.policy'],y=df['days.with.cr.line'])\n",
        "plt.title(\"Credit-approved users have a slightly higher days with credit line\", fontsize=15)\n",
        "plt.xlabel(\"Credit policy\",fontsize=15)\n",
        "plt.ylabel(\"Days with credit line\",fontsize=15)\n",
        "\n",
        "Text(0, 0.5, 'Days with credit line')\n",
        "\n",
        "\n",
        "sns.boxplot(x=df['credit.policy'],y=df['dti'])\n",
        "plt.title(\"Debt-to-income level does not make a big difference in credit approval odds\", fontsize=15)\n",
        "plt.xlabel(\"Credit policy\",fontsize=15)\n",
        "plt.ylabel(\"Debt-to-income ratio\",fontsize=15)\n",
        "\n",
        "Text(0, 0.5, 'Debt-to-income ratio')\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.countplot(x='purpose',hue='not.fully.paid',data=df, palette='Set1')\n",
        "plt.title(\"Bar chart of loan purpose colored by not fully paid status\", fontsize=17)\n",
        "plt.xlabel(\"Purpose\", fontsize=15)\n",
        "\n",
        "Text(0.5, 0, 'Purpose')\n",
        "\n",
        "\n",
        "sns.jointplot(x='fico',y='int.rate',data=df, color='purple', size=12)\n",
        "\n",
        "<seaborn.axisgrid.JointGrid at 0x78c12dba0a90>\n",
        "\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "sns.lmplot(y='int.rate', x='fico', data=df, hue='credit.policy',\n",
        "           col='not.fully.paid', palette='Set1', height=6)\n",
        "\n",
        "<seaborn.axisgrid.FacetGrid at 0x78c12d74efe0>\n",
        "\n",
        "\n",
        "df_final = pd.get_dummies(df,['purpose'],drop_first=True)\n",
        "\n",
        "\n",
        "df_final.head()\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X = df_final.drop('not.fully.paid',axis=1)\n",
        "y = df_final['not.fully.paid']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n",
        "\n",
        "\n",
        "X.head()\n",
        "\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "dtree = DecisionTreeClassifier(criterion='gini',max_depth=None)\n",
        "\n",
        "\n",
        "dtree.fit(X_train,y_train)\n",
        "\n",
        "DecisionTreeClassifier()\n",
        "In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.\n",
        "On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.\n",
        "\n",
        "predictions = dtree.predict(X_test)\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "\n",
        "\n",
        "print(classification_report(y_test,predictions))\n",
        "\n",
        "\n",
        "\n",
        "cm=confusion_matrix(y_test,predictions)\n",
        "print(cm)\n",
        "print (\"Accuracy of prediction:\",round((cm[0,0]+cm[1,1])/cm.sum(),3))\n",
        "\n",
        "[[2046  375]\n",
        " [ 356   97]]\n",
        "Accuracy of prediction: 0.746\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "rfc = RandomForestClassifier(n_estimators=600)\n",
        "\n",
        "\n",
        "rfc.fit(X_train, y_train)\n",
        "\n",
        "RandomForestClassifier(n_estimators=600)\n",
        "In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.\n",
        "On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.\n",
        "\n",
        "cr = classification_report(y_test,predictions)\n",
        "\n",
        "\n",
        "print(cr)\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "nsimu = 21\n",
        "accuracy=[0]*nsimu\n",
        "ntree = [0]*nsimu\n",
        "for i in range(1,nsimu):\n",
        "    rfc = RandomForestClassifier(n_estimators=i*5,min_samples_split=10,max_depth=None,criterion='gini')\n",
        "    rfc.fit(X_train, y_train)\n",
        "    rfc_pred = rfc.predict(X_test)\n",
        "    cm = confusion_matrix(y_test,rfc_pred)\n",
        "    accuracy[i] = (cm[0,0]+cm[1,1])/cm.sum()\n",
        "    ntree[i]=i*5\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.scatter(x=ntree[1:nsimu],y=accuracy[1:nsimu],s=60,c='red')\n",
        "plt.title(\"Number of trees in the Random Forest vs. prediction accuracy (criterion: 'gini')\", fontsize=18)\n",
        "plt.xlabel(\"Number of trees\", fontsize=15)\n",
        "plt.ylabel(\"Prediction accuracy from confusion matrix\", fontsize=15)\n",
        "\n",
        "Text(0, 0.5, 'Prediction accuracy from confusion matrix')\n",
        "\n",
        "\n",
        "nsimu = 21\n",
        "accuracy=[0]*nsimu\n",
        "ntree = [0]*nsimu\n",
        "for i in range(1,nsimu):\n",
        "    rfc = RandomForestClassifier(n_estimators=i*5,min_samples_split=10,max_depth=None,criterion='entropy')\n",
        "    rfc.fit(X_train, y_train)\n",
        "    rfc_pred = rfc.predict(X_test)\n",
        "    cm = confusion_matrix(y_test,rfc_pred)\n",
        "    accuracy[i] = (cm[0,0]+cm[1,1])/cm.sum()\n",
        "    ntree[i]=i*5\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.scatter(x=ntree[1:nsimu],y=accuracy[1:nsimu],s=60,c='red')\n",
        "plt.title(\"Number of trees in the Random Forest vs. prediction accuracy (criterion: 'entropy')\", fontsize=18)\n",
        "plt.xlabel(\"Number of trees\", fontsize=15)\n",
        "plt.ylabel(\"Prediction accuracy from confusion matrix\", fontsize=15)\n",
        "\n",
        "Text(0, 0.5, 'Prediction accuracy from confusion matrix')\n",
        "\n",
        "\n",
        "nsimu = 21\n",
        "accuracy=[0]*nsimu\n",
        "ntree = [0]*nsimu\n",
        "for i in range(1,nsimu):\n",
        "    rfc = RandomForestClassifier(n_estimators=i*5,min_samples_split=10,max_depth=None,criterion='gini')\n",
        "    rfc.fit(X_train, y_train)\n",
        "    rfc_pred = rfc.predict(X_test)\n",
        "    cm = confusion_matrix(y_test,rfc_pred)\n",
        "    accuracy[i] = (cm[0,0]+cm[1,1])/cm.sum()\n",
        "    ntree[i]=i*5\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.scatter(x=ntree[1:nsimu],y=accuracy[1:nsimu],s=60,c='red')\n",
        "plt.title(\"Number of trees in the Random Forest vs. prediction accuracy (max depth: None)\", fontsize=18)\n",
        "plt.xlabel(\"Number of trees\", fontsize=15)\n",
        "plt.ylabel(\"Prediction accuracy from confusion matrix\", fontsize=15)\n",
        "\n",
        "Text(0, 0.5, 'Prediction accuracy from confusion matrix')\n",
        "\n",
        "\n",
        "nsimu = 21\n",
        "accuracy=[0]*nsimu\n",
        "ntree = [0]*nsimu\n",
        "for i in range(1,nsimu):\n",
        "    rfc = RandomForestClassifier(n_estimators=i*5,min_samples_split=10,max_depth=5,criterion='gini')\n",
        "    rfc.fit(X_train, y_train)\n",
        "    rfc_pred = rfc.predict(X_test)\n",
        "    cm = confusion_matrix(y_test,rfc_pred)\n",
        "    accuracy[i] = (cm[0,0]+cm[1,1])/cm.sum()\n",
        "    ntree[i]=i*5\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.scatter(x=ntree[1:nsimu],y=accuracy[1:nsimu],s=60,c='red')\n",
        "plt.title(\"Number of trees in the Random Forest vs. prediction accuracy (max depth: 5)\", fontsize=18)\n",
        "plt.xlabel(\"Number of trees\", fontsize=15)\n",
        "plt.ylabel(\"Prediction accuracy from confusion matrix\", fontsize=15)\n",
        "\n",
        "Text(0, 0.5, 'Prediction accuracy from confusion matrix')\n",
        "\n",
        "\n",
        "nsimu = 21\n",
        "accuracy=[0]*nsimu\n",
        "ntree = [0]*nsimu\n",
        "for i in range(1,nsimu):\n",
        "    rfc = RandomForestClassifier(n_estimators=i*5,min_samples_split=2,max_depth=None,criterion='gini')\n",
        "    rfc.fit(X_train, y_train)\n",
        "    rfc_pred = rfc.predict(X_test)\n",
        "    cm = confusion_matrix(y_test,rfc_pred)\n",
        "    accuracy[i] = (cm[0,0]+cm[1,1])/cm.sum()\n",
        "    ntree[i]=i*5\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.scatter(x=ntree[1:nsimu],y=accuracy[1:nsimu],s=60,c='red')\n",
        "plt.title(\"Number of trees in the Random Forest vs. prediction accuracy (minimum sample split: 2)\", fontsize=18)\n",
        "plt.xlabel(\"Number of trees\", fontsize=15)\n",
        "plt.ylabel(\"Prediction accuracy from confusion matrix\", fontsize=15)\n",
        "\n",
        "Text(0, 0.5, 'Prediction accuracy from confusion matrix')\n",
        "\n",
        "\n",
        "nsimu = 21\n",
        "accuracy=[0]*nsimu\n",
        "ntree = [0]*nsimu\n",
        "for i in range(1,nsimu):\n",
        "    rfc = RandomForestClassifier(n_estimators=i*5,min_samples_split=20,max_depth=None,criterion='gini')\n",
        "    rfc.fit(X_train, y_train)\n",
        "    rfc_pred = rfc.predict(X_test)\n",
        "    cm = confusion_matrix(y_test,rfc_pred)\n",
        "    accuracy[i] = (cm[0,0]+cm[1,1])/cm.sum()\n",
        "    ntree[i]=i*5\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.scatter(x=ntree[1:nsimu],y=accuracy[1:nsimu],s=60,c='red')\n",
        "plt.title(\"Number of trees in the Random Forest vs. prediction accuracy (minimum sample split: 20)\", fontsize=18)\n",
        "plt.xlabel(\"Number of trees\", fontsize=15)\n",
        "plt.ylabel(\"Prediction accuracy from confusion matrix\", fontsize=15)\n",
        "\n",
        "Text(0, 0.5, 'Prediction accuracy from confusion matrix')\n"
      ],
      "metadata": {
        "id": "JSzB6XfYPmh7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}